{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5434d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4b78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70202ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"human\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServe는 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff33d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1a5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='LangServe는 개발자가 대규모 언어 모델(LLM)을 쉽게 배포하고 관리할 수 있도록 도와주는 플랫폼입니다. LangServe는 언어 모델의 개발, 테스트, 배포 및 운영을 간소화하여 개발자가 더 효율적으로 작업할 수 있도록 지원합니다.\\n\\nLangServe의 주요 기능은 다음과 같습니다:\\n\\n1. **언어 모델 배포**: LangServe를 사용하면 개발자가 언어 모델을 쉽게 배포할 수 있습니다. LangServe는 다양한 클라우드 플랫폼과 호환되며, 개발자는 자신의 언어 모델을 클라우드 환경에서 빠르게 배포할 수 있습니다.\\n\\n2. **모델 관리**: LangServe는 언어 모델의 버전을 관리하고, 모델의 성능을 모니터링하며, 필요에 따라 모델을 업데이트할 수 있는 기능을 제공합니다. 이를 통해 개발자는 모델의 성능을 지속적으로 개선할 수 있습니다.\\n\\n3. **API 제공**: LangServe는 언어 모델을 API로 제공하여 다른 애플리케이션에서 쉽게 사용할 수 있도록 합니다. 이는 개발자가 언어 모델을 다른 서비스에 통합할 때 매우 유용합니다.\\n\\n4. ** 보안 및 인증**: LangServe는 언어 모델의 배포 및 사용에 필요한 보안 및 인증 기능을 제공합니다. 이를 통해 개발자는 자신의 모델이 안전하게 사용되고 있는지 확인할 수 있습니다.\\n\\n5. **확장성**: LangServe는 수평적 확장성을 지원하여, 대규모 언어 모델도 빠르게 처리할 수 있습니다. 이는 대용량 데이터를 처리해야 하는 애플리케이션에 매우 중요합니다.\\n\\n6. **모니터링 및 로그**: LangServe는 모델의 성능과 사용량을 모니터링하고, 로그를 제공하여 문제 발생 시 빠르게 진단하고 해결할 수 있도록 돕습니다.\\n\\n7. **커뮤니티 지원**: LangServe는 개발자 커뮤니티를 지원하여, 사용자들끼리 경험을 공유하고 서로 도움을 줄 수 있는 플랫폼을 제공합니다.\\n\\nLangServe를 이용하면 개발자는 언어 모델의 개발과 배포에 집중할 수 있으며, 인프라 관리에 드는 시간을 줄일 수 있습니다. 따라서 LangServe는 자연어 처리(NLP) 및 인공지능(AI) 개발자에게 매우 유용한 도구입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 412, 'prompt_tokens': 30, 'total_tokens': 442, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 2.232074768, 'prompt_time': 0.003217572, 'completion_time': 0.993011736, 'total_time': 0.996229308}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-06a89fb1-0a90-41e8-ba38-d43c337e2b38', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--5cde5307-6bd5-4d35-a018-1efacd7d2a80-0' usage_metadata={'input_tokens': 30, 'output_tokens': 412, 'total_tokens': 442, 'input_token_details': {}, 'output_token_details': {}}\n",
      "응답: LangServe는 개발자가 대규모 언어 모델(LLM)을 쉽게 배포하고 관리할 수 있도록 도와주는 플랫폼입니다. LangServe는 언어 모델의 개발, 테스트, 배포 및 운영을 간소화하여 개발자가 더 효율적으로 작업할 수 있도록 지원합니다.\n",
      "\n",
      "LangServe의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **언어 모델 배포**: LangServe를 사용하면 개발자가 언어 모델을 쉽게 배포할 수 있습니다. LangServe는 다양한 클라우드 플랫폼과 호환되며, 개발자는 자신의 언어 모델을 클라우드 환경에서 빠르게 배포할 수 있습니다.\n",
      "\n",
      "2. **모델 관리**: LangServe는 언어 모델의 버전을 관리하고, 모델의 성능을 모니터링하며, 필요에 따라 모델을 업데이트할 수 있는 기능을 제공합니다. 이를 통해 개발자는 모델의 성능을 지속적으로 개선할 수 있습니다.\n",
      "\n",
      "3. **API 제공**: LangServe는 언어 모델을 API로 제공하여 다른 애플리케이션에서 쉽게 사용할 수 있도록 합니다. 이는 개발자가 언어 모델을 다른 서비스에 통합할 때 매우 유용합니다.\n",
      "\n",
      "4. ** 보안 및 인증**: LangServe는 언어 모델의 배포 및 사용에 필요한 보안 및 인증 기능을 제공합니다. 이를 통해 개발자는 자신의 모델이 안전하게 사용되고 있는지 확인할 수 있습니다.\n",
      "\n",
      "5. **확장성**: LangServe는 수평적 확장성을 지원하여, 대규모 언어 모델도 빠르게 처리할 수 있습니다. 이는 대용량 데이터를 처리해야 하는 애플리케이션에 매우 중요합니다.\n",
      "\n",
      "6. **모니터링 및 로그**: LangServe는 모델의 성능과 사용량을 모니터링하고, 로그를 제공하여 문제 발생 시 빠르게 진단하고 해결할 수 있도록 돕습니다.\n",
      "\n",
      "7. **커뮤니티 지원**: LangServe는 개발자 커뮤니티를 지원하여, 사용자들끼리 경험을 공유하고 서로 도움을 줄 수 있는 플랫폼을 제공합니다.\n",
      "\n",
      "LangServe를 이용하면 개발자는 언어 모델의 개발과 배포에 집중할 수 있으며, 인프라 관리에 드는 시간을 줄일 수 있습니다. 따라서 LangServe는 자연어 처리(NLP) 및 인공지능(AI) 개발자에게 매우 유용한 도구입니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(response)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafbd5a1",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c34c649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 반드시 한글로 설명해주세요.\")\\n    ')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 반드시 한글로 설명해주세요.\")\n",
    "    \"\"\")                                     \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d392dedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL) prompt + llm 연결\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58cf5be",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OutputParser을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbba4772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL) prompt + llm + outputparser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084bfec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 컴퓨터가 데이터를 통해 스스로 학습하고 발전하는 과정입니다. 이는 마치 어린 아이가 사물을 인식하고 학습하는 방식과 유사합니다.\n",
      "\n",
      "**기본 개념**\n",
      "\n",
      "인공지능 모델은 크게 세 가지 요소로 구성됩니다.\n",
      "\n",
      "1. **데이터**: 인공지능 모델이 학습하는 데 필요한 정보입니다. 데이터는 크게 **입력 데이터**와 **출력 데이터**로 나뉩니다.\n",
      "2. **모델**: 데이터를 처리하고 학습하는 알고리즘입니다. 모델은 데이터를 분석하고 패턴을 찾아냅니다.\n",
      "3. **손실 함수**: 모델의 성능을 평가하는 지표입니다. 손실 함수는 모델의 예측 결과와 실제 출력 데이터 간의 차이를 측정합니다.\n",
      "\n",
      "**학습 과정**\n",
      "\n",
      "인공지능 모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 다양한 소스에서 데이터를 수집합니다.\n",
      "2. **데이터 전처리**: 수집한 데이터를 깨끗하고 사용 가능한 형태로 변환합니다.\n",
      "3. **모델 초기화**: 모델을 초기화하고 학습을 시작합니다.\n",
      "4. **예측**: 모델은 입력 데이터를 받아 예측 결과를 출력합니다.\n",
      "5. **손실 계산**: 손실 함수를 통해 예측 결과와 실제 출력 데이터 간의 차이를 계산합니다.\n",
      "6. **모델 업데이트**: 모델은 손실 함수를 최소화하기 위해 가중치를 업데이트합니다.\n",
      "7. **반복**: 4~6단계를 반복하며 모델을 학습합니다.\n",
      "\n",
      "**주요 학습 원리**\n",
      "\n",
      "인공지능 모델의 학습 원리는 크게 두 가지로 나눌 수 있습니다.\n",
      "\n",
      "1. **지도 학습**: 모델이 입력 데이터와 출력 데이터 쌍을 통해 학습하는 방식입니다. 모델은 입력 데이터를 받아 출력 데이터를 예측하고, 실제 출력 데이터와의 차이를 최소화합니다.\n",
      "2. **비지도 학습**: 모델이 입력 데이터만으로 학습하는 방식입니다. 모델은 입력 데이터의 패턴이나 구조를 찾아냅니다.\n",
      "\n",
      "**최적화 기법**\n",
      "\n",
      "인공지능 모델의 학습에는 다양한 최적화 기법이 사용됩니다. 대표적인 기법으로는 다음과 같습니다.\n",
      "\n",
      "1. **경사 하강법**: 손실 함수를 최소화하기 위해 모델의 가중치를 업데이트하는 기법입니다.\n",
      "2. **확률적 경사 하강법**: 경사 하강법을 변형하여 모델의 가중치를 업데이트하는 기법입니다.\n",
      "\n",
      "인공지능 모델의 학습 원리를 이해하면, 데이터와 모델을 통해 컴퓨터가 스스로 학습하고 발전하는 과정을 알 수 있습니다. 이를 통해 인공지능 기술의 기본 개념을 쉽게 이해할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33153ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 인공지능(AI) 모델을 활용하여 자연어 처리(NLP) 및 대화형 AI 시스템을 구축하기 위한 플랫폼을 제공하는 회사입니다. LangChain의 주요 제품은 다음과 같습니다.\n",
      "\n",
      "1. **LangSmith**: 랭스미스는 랭체인에서 제공하는 대화형 AI 모델 개발 및 관리 플랫폼입니다. 이 플랫폼을 통해 개발자는 대화형 AI 모델을 쉽게 구축, 테스트 및 배포할 수 있습니다. 랭스미스는 대화형 AI 모델의 성능을 평가하고 개선하는 데 도움이 되는 다양한 도구와 기능을 제공합니다.\n",
      "\n",
      "2. **LangServe**: 랭서브는 랭체인에서 제공하는 API 기반의 대화형 AI 모델 배포 및 관리 서비스입니다. 이 서비스를 통해 개발자는 랭체인에서 지원하는 다양한 대화형 AI 모델을 쉽게 통합하고 배포할 수 있습니다. 랭서브는 대화형 AI 모델의 성능을 모니터링하고 관리하는 데 도움이 되는 다양한 기능과 도구를 제공합니다.\n",
      "\n",
      "LangChain의 제품들은 대화형 AI 시스템을 구축하고 관리하는 데 필요한 다양한 도구와 기능을 제공하며, 개발자가 보다 쉽게 대화형 AI 모델을 구축하고 배포할 수 있도록 지원합니다.\n",
      "\n",
      "LangChain의 제품들은 다음과 같은 특징을 가지고 있습니다.\n",
      "\n",
      "* **쉬운 개발 및 배포**: 랭체인 제품들은 대화형 AI 모델을 쉽게 구축, 테스트 및 배포할 수 있는 도구와 기능을 제공합니다.\n",
      "* **성능 평가 및 개선**: 랭체인 제품들은 대화형 AI 모델의 성능을 평가하고 개선하는 데 도움이 되는 다양한 도구와 기능을 제공합니다.\n",
      "* **확장성 및 유연성**: 랭체인 제품들은 다양한 대화형 AI 모델을 지원하며, 개발자가 쉽게 통합하고 배포할 수 있습니다.\n",
      "\n",
      "LangChain의 제품들은 대화형 AI 시스템을 구축하고 관리하는 데 필요한 다양한 요구사항을 충족시키며, 개발자가 보다 쉽게 대화형 AI 모델을 구축하고 배포할 수 있도록 지원합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \": LangChain의 Products(제품)는 어떤 것들이 있나요? 예를 들어 LangSmith, LangServe 같은 Product가 있어\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be77c69",
   "metadata": {},
   "source": [
    "### Runnable의 stream() 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33721597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 컴퓨터가 데이터를 통해 스스로 학습하고, 이를 바탕으로 예측이나 분류 작업을 수행하는 과정입니다. 이를 이해하기 위해, 먼저 인공지능 모델의 기본 개념과 학습 과정에 대해 설명하겠습니다.\n",
      "\n",
      "### 1. 인공지능 모델이란?\n",
      "\n",
      "인공지능 모델은 주어진 데이터로부터 학습을 통해 패턴이나 관계를 발견하고, 이를 기반으로 새로운 데이터에 대해 예측하거나 분류하는 알고리즘입니다. 이러한 모델에는 신경망, 결정 트리, 서포트 벡터 머신 등 여러 종류가 있습니다.\n",
      "\n",
      "### 2. 학습 데이터\n",
      "\n",
      "인공지능 모델의 학습은 데이터로부터 시작됩니다. 학습 데이터는 입력 데이터와 그에 대응하는 결과(레이블)로 구성됩니다. 예를 들어, 고양이와 개의 사진을 분류하는 모델을 학습시킬 때는, 사진(입력 데이터)과 사진에 대한 설명(레이블, 고양이 또는 개)이 필요합니다.\n",
      "\n",
      "### 3. 모델의 학습 과정\n",
      "\n",
      "모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "#### (1) 데이터 준비\n",
      "\n",
      "- **데이터 수집**: 다양한 소스로부터 관련 데이터를 수집합니다.\n",
      "- **데이터 전처리**: 데이터를 모델에 적합한 형태로 변환합니다. 여기에는 데이터 정리, 변환, 정규화 등이 포함됩니다.\n",
      "\n",
      "#### (2) 모델 선택\n",
      "\n",
      "- 문제의 성격에 따라 적합한 모델을 선택합니다. 예를 들어, 이미지 분류에는 합성곱 신경망(CNN), 자연어 처리에는 순환 신경망(RNN)이나 트랜스포머 등이 적합합니다.\n",
      "\n",
      "#### (3) 모델 학습\n",
      "\n",
      "- **모델 초기화**: 모델의 가중치를 무작위로 초기화합니다.\n",
      "- **순전파(Forward Pass)**: 입력 데이터를 모델에 통과시켜 예측값을 얻습니다.\n",
      "- **손실 함수 계산**: 예측값과 실제값(레이블) 사이의 차이를 계산합니다. 손실 함수는 모델의 성능을 평가하는 지표입니다.\n",
      "- **역전파(Backward Pass)**: 손실 함수를 최소화하기 위해, 예측값과 실제값의 차이(오차)를 모델의 각 가중치에 대해 계산합니다. 이를 통해 가중치를 업데이트할 방향을 결정합니다.\n",
      "- **가중치 업데이트**: 계산된 오차를 바탕으로 가중치를 조정합니다. 이 과정은 최적화 알고리즘(예: SGD, Adam)에 의해 수행됩니다.\n",
      "\n",
      "#### (4) 모델 평가\n",
      "\n",
      "- 학습된 모델의 성능을 평가합니다. 이를 위해, 별도의 테스트 데이터를 사용합니다. 모델의 성능이 만족할 만한 수준에 도달할 때까지 학습 과정을 반복합니다.\n",
      "\n",
      "### 4. 핵심 개념\n",
      "\n",
      "- **과적합(Overfitting)**: 모델이 학습 데이터에 너무 특화되어 새로운 데이터에 대한 일반화 성능이 떨어지는 현상. 이를 방지하기 위해 정규화, 드롭아웃 등의 기법을 사용합니다.\n",
      "- **비용 함수(Loss Function)**: 모델의 예측값과 실제값 사이의 차이를 측정하는 함수. 모델 학습의 목표는 이 비용 함수를 최소화하는 것입니다.\n",
      "\n",
      "### 5. 결론\n",
      "\n",
      "인공지능 모델의 학습 원리는 데이터를 통해 모델이 스스로 학습하고, 이를 바탕으로 새로운 데이터에 대해 예측이나 분류를 수행하는 능력입니다. 이를 위해 적절한 데이터를 수집하고, 모델을 선택하며, 반복적인 학습 과정을 통해 모델의 가중치를 최적화합니다. 이렇게 학습된 모델은 다양한 분야에서 활용되고 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해 주세요.\"})\n",
    "    \n",
    "    # 스트리밍 출력\n",
    "    #print(answer)\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852fbba4",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* 첫번째 Chain의 출력이, 두번째 Chain의 입력이 된다.\n",
    "* 두개의 Chain과 Prompt + OutputParser를 LCEL로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd14ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 한국 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 10문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00dffbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  **영화 제목**: 범죄도시2 (2022)\n",
      "\n",
      "2.  **영화 줄거리 요약**:\n",
      "\n",
      "    *   마석도는 서울 광수대와 협조하여 베트남 마약 조직에 대한 수사에 나선다.\n",
      "    *   마석도는 광수대와 함께 베트남 마약 조직의 국내 잠복까지 수사에 나선다.\n",
      "    *   마석도는 베트남 마약 조직의 국내 잠복을 조사하는 과정에서 여러 차례의 충돌을 겪는다.\n",
      "    *   마석도는 광수대와 함께 베트남 마약 조직의 국내 잠복과 관련된 범죄자들을 체포하기 위해 노력한다.\n",
      "    *   베트남 마약 조직의 국내 잠복을 조사하는 과정에서 마석도는 장첸과 그의 조직을 만나게 된다.\n",
      "    *   마석도는 장첸과 그의 조직을 상대로 강력한 액션을 펼치며 수사를 진행한다.\n",
      "    *   마석도는 장첸과 그의 조직을 상대로 치열한 대결을 벌이며 수사를 진행한다.\n",
      "    *   마석도는 장첸과 그의 조직을 상대로 강력한 액션을 펼치며 많은 범죄자를 체포하는 데 성공한다.\n",
      "    *   마석도는 장첸과 그의 조직을 상대로 치열한 대결을 벌이며 수사를 진행하고, 많은 범죄자를 체포하는 데 성공한다.\n",
      "    *   마석도는 장첸과 그의 조직을 상대로 강력한 액션을 펼치며 많은 범죄자를 체포하는 데 성공하고, 수사는 마무리된다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 입력 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"액션\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa9bc7",
   "metadata": {},
   "source": [
    "### PromptTemplate 여러개 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa4dde91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "ChatGPT는 대규모 언어 데이터를 기반으로 학습된 인공지능 모델로, 주어진 문맥에 따라 적절한 응답을 생성할 수 있습니다. 이 모델은 강화 학습을 통해 인간과의 대화 데이터를 학습하고, 이를 통해 자연스러운 대화 흐름을 이해하고 응답을 생성합니다. 학습 과정에서 모델은 오류를 최소화하기 위해 지속적으로 업데이트되며, 이를 통해 성능이 향상됩니다.\n",
      "\n",
      "ChatGPT 모델의 장점은 다음과 같습니다.\n",
      "\n",
      "*   자연스러운 대화가 가능하며, 상황에 맞는 적절한 응답을 제공합니다.\n",
      "*   대규모 언어 데이터를 기반으로 학습되어 다양한 주제와 상황에 대한 지식을 갖추고 있습니다.\n",
      "*   사용자와의 상호작용을 통해 지속적으로 학습하고 성능을 향상시킬 수 있습니다.\n",
      "\n",
      "ChatGPT 모델과 비슷한 AI 모델로는  LaMDA, LLaMA, PaLM 등이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "229b429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 요약해서 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 요약해서 한국어로 답변해 주세요.', 'llama-4 모델의 학습 원리를 4 문장으로 요약해서 한국어로 답변해 주세요.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab54a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 모델은 대규모의 텍스트 데이터를 학습하여 언어 패턴과 구조를 익히는 방식으로 훈련됩니다. 이 모델은 주어진 문맥에서 다음에 올 가능성이 높은 단어를 예측하도록 스스로 학습하며, 이를 통해 자연스러운 텍스트를 생성하거나 대화에 참여할 수 있습니다.\n",
      "Gemma는 컴퓨터가 자연어 처리를 더 잘하도록 설계된 인공지능(AI) 언어 모델입니다. 대규모의 텍스트 데이터를 학습하여 언어의 패턴과 구조를 이해하고, 이를 바탕으로 질문에 답변하거나 텍스트를 생성하는 등의 작업을 수행할 수 있습니다. Gemma는 사전 학습된 언어 모델을 미세 조정하여 특정 작업에 맞게 조정할 수 있으며, 이를 통해 성능을 더욱 향상시킬 수 있습니다.\n",
      "llama-4 모델은 페이스북의 메타에서 개발한 대규모 언어 모델입니다. 이 모델은 수십억 개의 매개변수를 가지고 있으며, 방대한 양의 텍스트 데이터를 학습하여 자연어 처리 능력을 습득합니다. 학습 과정에서 모델은 주어진 문맥에서 다음에 올 단어를 예측하도록 훈련되며, 이를 통해 언어의 패턴과 구조를 학습합니다. 이를 통해 llama-4 모델은 다양한 자연어 처리 작업에 활용될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt) #AIMessage\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde20ca",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate \n",
    "* SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a599596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "딥러닝은 인공신경망을 기반으로 하는 머신러닝의 한 분야입니다. 인공신경망은 인간의 뇌를 모방한 구조로, 데이터를 처리하고 학습하는 방식입니다. 딥러닝은 이러한 인공신경망을 깊게 쌓아서 복잡한 데이터를 분석하고 학습하는 기술입니다.\n",
      "\n",
      "딥러닝은 데이터에서 패턴을 발견하고, 이미지를 인식하거나, 자연어 처리를 수행하는 등 다양한 작업에 사용됩니다. 예를 들어, 이미지 인식, 음성 인식, 자연어 번역, 그리고 자율 주행 자동차 등의 분야에서 사용됩니다.\n",
      "\n",
      "딥러닝의 핵심 아이디어는 데이터에서 특징을 자동으로 추출하고, 이를 통해 학습하는 것입니다. 이를 위해 딥러닝 모델은 여러 개의 레이어로 구성되어 있으며, 각 레이어는 데이터에서 특징을 추출하고 이를 다음 레이어로 전달합니다.\n",
      "\n",
      "딥러닝의 대표적인 알고리즘으로는 합성곱 신경망 (Convolutional Neural Network, CNN), 순환 신경망 (Recurrent Neural Network, RNN), 그리고 심층 신경망 (Deep Neural Network, DNN) 등이 있습니다.\n",
      "\n",
      "딥러닝은 많은 양의 데이터를 필요로 하며, 이를 통해 모델을 학습시키고 개선할 수 있습니다. 따라서 빅데이터와 컴퓨팅 파워가 필수적인 요소입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 {topic} 전문가입니다. 명확하고 자세하게 한국어로 설명해 주세요.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝은 무엇인가요?\")\n",
    "\n",
    "# LLM 호출\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e30e81",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "* 예시를 제공 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7173be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 태양계의 행성\n",
      "1. **수성**: 태양과 가장 가까운 행성으로 매우 작고 온도가 극심하게 변합니다.\n",
      "2. **금성**: 밝고 뜨거운 행성으로 강한 온실 효과로 표면 온도가 매우 높습니다.\n",
      "3. **지구**: 생명체가 존재하는 유일한 행성으로 대기와 물이 있습니다.\n",
      "4. **화성**: 붉은 행성으로 미래에 인간이 탐사할 가능성이 있습니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성으로 가스 행성입니다.\n",
      "6. **토성**: 아름다운 고리를 가진 가스 행성입니다.\n",
      "7. **천왕성**: 빙하 행성으로 자전축이 기울어져 있습니다.\n",
      "8. **해왕성**: 가장 먼 행성으로 강한 바람이 불고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
