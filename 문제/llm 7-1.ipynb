{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83881ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "# API í‚¤ê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ì½”ë“œ (ì„ íƒ ì‚¬í•­ì´ì§€ë§Œ ì¶”ì²œ)\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "    raise ValueError(\"GROQ_API_KEYê°€ .env íŒŒì¼ì— ì—†ê±°ë‚˜ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74016456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¹´í˜ ë©”ë‰´ ë°ì´í„°ë¥¼ íŒŒì¼ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\n",
      "âœ… FAISS Vector DB ì¸ë±ì‹± ë° Retriever ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "===== ì‚¬ìš©ì ì§ˆë¬¸: ë‹¬ë‹¬í•˜ê³  ë¶€ë“œëŸ¬ìš´ ì»¤í”¼ ë­ ìˆì–´? =====\n",
      "\n",
      "--- Agent ë…¸ë“œ ì‹¤í–‰ ---\n",
      "--- Vector DB ê²€ìƒ‰ ì‹¤í–‰: retriever.invoke(query='ë‹¬ë‹¬í•˜ê³  ë¶€ë“œëŸ¬ìš´ ì»¤í”¼') ---\n",
      "--- Agent ë…¸ë“œ ì‹¤í–‰ ---\n",
      "--- ìµœì¢… ë‹µë³€ ìƒì„± ---\n",
      "ğŸ¤– ì¹´í˜ë´‡ì˜ ë‹µë³€:\n",
      "\n",
      "ë‹¬ë‹¬í•˜ê³  ë¶€ë“œëŸ¬ìš´ ì»¤í”¼ë¥¼ ì°¾ìœ¼ì‹  ê²ƒì€ìš”! ì¹´í˜ ë¼ë–¼ê°€ ì¢‹ì€ ì„ íƒì´ ë  ë“¯í•©ë‹ˆë‹¤. ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ì—ìŠ¤í”„ë ˆì†Œì˜ ì¡°í™”ë¥¼ ì˜ ëŠë¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ê²©ì€ â‚©4,500ì…ë‹ˆë‹¤.\n",
      "\n",
      "===== ì‚¬ìš©ì ì§ˆë¬¸: í‹°ë¼ë¯¸ìˆ˜ ì¼€ì´í¬ì— ëŒ€í•´ ì•Œë ¤ì¤˜ =====\n",
      "\n",
      "--- Agent ë…¸ë“œ ì‹¤í–‰ ---\n",
      "--- Vector DB ê²€ìƒ‰ ì‹¤í–‰: retriever.invoke(query='í‹°ë¼ë¯¸ìˆ˜ ì¼€ì´í¬') ---\n",
      "--- Agent ë…¸ë“œ ì‹¤í–‰ ---\n",
      "--- ìµœì¢… ë‹µë³€ ìƒì„± ---\n",
      "ğŸ¤– ì¹´í˜ë´‡ì˜ ë‹µë³€:\n",
      "\n",
      "í‹°ë¼ë¯¸ìˆ˜ ì¼€ì´í¬ëŠ” ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ìœ ì‚¬í•œ ë©”ë‰´ê°€ ìˆìŠµë‹ˆë‹¤.ãƒì¦ˆ ì¼€ì´í¬ëŠ” ë¶€ë“œëŸ½ê³  ì§„í•œ ì¹˜ì¦ˆì˜ ë§›ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ˆì½œë¦¿ ë¼ë–¼ëŠ” ì§„í•œ ì´ˆì½œë¦¿ê³¼ ìš°ìœ ê°€ ë§Œë‚œ ìŒë£Œì…ë‹ˆë‹¤. Would you like to try one of these options?\n"
     ]
    }
   ],
   "source": [
    "# === 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì„¤ì • (Vector DB ê´€ë ¨ ì¶”ê°€) ===\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings # ì„ë² ë”©ì„ ìœ„í•´ ì¶”ê°€\n",
    "from langchain_community.vectorstores import FAISS # Vector DBë¡œ FAISS ì¶”ê°€\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, BaseMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# --- .env íŒŒì¼ ë¡œë“œ ---\n",
    "load_dotenv()\n",
    "# Vector DBì—ì„œ ì‚¬ìš©í•  OpenAI API í‚¤ë„ í™•ì¸\n",
    "for key in [\"GROQ_API_KEY\", \"OPENAI_API_KEY\"]:\n",
    "    if not os.environ.get(key):\n",
    "        raise ValueError(f\"{key}ê°€ .env íŒŒì¼ì— ì—†ê±°ë‚˜ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# === 2. íŒŒì¼ ë°ì´í„° ë¡œë“œ ë° Vector DB ì´ˆê¸°í™” (ìˆ˜ì •ëœ ë¶€ë¶„) ===\n",
    "def parse_menu_file(file_path: str) -> dict:\n",
    "    # (ì´ì „ê³¼ ë™ì¼í•œ ì»¤ìŠ¤í…€ íŒŒì„œ)\n",
    "    menu_db = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or ':' not in line: continue\n",
    "            menu_name, details = [part.strip() for part in line.split(':', 1)]\n",
    "            if 'â‚©' in details:\n",
    "                description, price = [part.strip() for part in details.rsplit('â‚©', 1)]\n",
    "                price = 'â‚©' + price\n",
    "            else:\n",
    "                description = details\n",
    "                price = \"ê°€ê²© ì •ë³´ ì—†ìŒ\"\n",
    "            menu_db[menu_name] = {\"ê°€ê²©\": price, \"ì„¤ëª…\": description}\n",
    "    return menu_db\n",
    "\n",
    "try:\n",
    "    cafe_menu_db = parse_menu_file('../data/cafe_menu_data.txt')\n",
    "    print(\"âœ… ì¹´í˜ ë©”ë‰´ ë°ì´í„°ë¥¼ íŒŒì¼ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
    "except FileNotFoundError:\n",
    "    raise ValueError(\"`../data/cafe_menu_data.txt` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# [ìƒˆë¡œìš´ ë¶€ë¶„] Vector DB ì¸ë±ìŠ¤ ìƒì„±\n",
    "documents = []\n",
    "for menu_name, details in cafe_menu_db.items():\n",
    "    # Vector DBì— ì €ì¥í•  Document ê°ì²´ ìƒì„±\n",
    "    content = f\"ë©”ë‰´ëª…: {menu_name}\\nê°€ê²©: {details['ê°€ê²©']}\\nì„¤ëª…: {details['ì„¤ëª…']}\"\n",
    "    doc = Document(page_content=content, metadata={\"menu_name\": menu_name})\n",
    "    documents.append(doc)\n",
    "\n",
    "# OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# FAISS Vector Storeì— documentsë¥¼ ì„ë² ë”©í•˜ì—¬ ì €ì¥\n",
    "vector_store = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# retriever ìƒì„± (ìœ ì‚¬ë„ ë†’ì€ ìƒìœ„ 2ê°œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì •)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "print(\"âœ… FAISS Vector DB ì¸ë±ì‹± ë° Retriever ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# === 3. ì¹´í˜ ë©”ë‰´ ê²€ìƒ‰ ë„êµ¬ ìˆ˜ì • (Vector DB Retriever ì‚¬ìš©) ===\n",
    "@tool\n",
    "def search_cafe_menu(query: str) -> str:\n",
    "    \"\"\"ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ì¹´í˜ ë©”ë‰´(ìŒë£Œ ë˜ëŠ” ë””ì €íŠ¸)ì™€ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë©”ë‰´ ì •ë³´ë¥¼ Vector DBì—ì„œ ì°¾ìŠµë‹ˆë‹¤.\"\"\"\n",
    "    print(f\"--- Vector DB ê²€ìƒ‰ ì‹¤í–‰: retriever.invoke(query='{query}') ---\")\n",
    "    \n",
    "    # retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        return f\"'{query}'ì™€ ê´€ë ¨ëœ ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì •ë¦¬í•˜ì—¬ ë°˜í™˜\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "\n",
    "# === 4. ~ 8. ë‚˜ë¨¸ì§€ Agent ë¡œì§ì€ ì´ì „ê³¼ ì™„ì „íˆ ë™ì¼í•©ë‹ˆë‹¤. ===\n",
    "# (AgentëŠ” ë„êµ¬ì˜ ë‚´ë¶€ êµ¬í˜„ì´ ì–´ë–»ê²Œ ë°”ë€Œì—ˆëŠ”ì§€ ì „í˜€ ì‹ ê²½ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤.)\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    pass\n",
    "\n",
    "tools = [search_cafe_menu]\n",
    "llm = ChatGroq(model_name=\"llama3-8b-8192\")\n",
    "system_prompt = (\n",
    "    \"ë‹¹ì‹ ì€ 'ì¹´í˜ë´‡'ì´ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ ì¹œì ˆí•œ ì¹´í˜ ì§ì› Agentì…ë‹ˆë‹¤. \"\n",
    "    \"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ `search_cafe_menu` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. \"\n",
    "    \"ë„êµ¬ ì‚¬ìš© í›„ì—ëŠ”, ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€ì„ ì •ë¦¬í•´ì„œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. \"\n",
    "    \"--- \\n\"\n",
    "    \"**ë§¤ìš° ì¤‘ìš”: ì‚¬ìš©ìì˜ ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.**\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "agent_runnable = prompt | llm.bind_tools(tools)\n",
    "def call_agent_node(state: AgentState):\n",
    "    print(\"--- Agent ë…¸ë“œ ì‹¤í–‰ ---\")\n",
    "    response = agent_runnable.invoke(state)\n",
    "    return {\"messages\": [response]}\n",
    "tool_node = ToolNode(tools)\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"final_answer\"\n",
    "def format_final_response(state: AgentState):\n",
    "    print(\"--- ìµœì¢… ë‹µë³€ ìƒì„± ---\")\n",
    "    final_answer: AIMessage = state[\"messages\"][-1]\n",
    "    clean_content = final_answer.content.replace('<tool-use>{\"tool_calls\":[]}</tool-use>', '').strip()\n",
    "    if clean_content:\n",
    "        print(\"ğŸ¤– ì¹´í˜ë´‡ì˜ ë‹µë³€:\\n\\n\" + clean_content)\n",
    "    else:\n",
    "        print(\"ğŸ¤– ì¹´í˜ë´‡: ë” ì´ìƒ ë“œë¦´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    return {\"messages\": [final_answer]}\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"agent\", call_agent_node)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_node(\"final_answer\", format_final_response)\n",
    "builder.set_entry_point(\"agent\")\n",
    "builder.add_conditional_edges(\"agent\", should_continue)\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "builder.add_edge(\"final_answer\", END)\n",
    "graph = builder.compile()\n",
    "def run_agent(question: str):\n",
    "    print(f\"\\n===== ì‚¬ìš©ì ì§ˆë¬¸: {question} =====\\n\")\n",
    "    inputs = {\"messages\": [HumanMessage(content=question)]}\n",
    "    graph.invoke(inputs, {\"recursion_limit\": 10})\n",
    "\n",
    "try:\n",
    "    run_agent(\"ë‹¬ë‹¬í•˜ê³  ë¶€ë“œëŸ¬ìš´ ì»¤í”¼ ë­ ìˆì–´?\")\n",
    "    run_agent(\"í‹°ë¼ë¯¸ìˆ˜ ì¼€ì´í¬ì— ëŒ€í•´ ì•Œë ¤ì¤˜\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
