{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66bf7e4",
   "metadata": {},
   "source": [
    "### 문제 6-1 : 조건부 분기가 있는 메뉴 추천 시스템 ( LangGraph 사용하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 벡터 DB가 이미 존재합니다.\n",
      "Ollama Embeddings 모델 (bge-m3)을 사용하여 벡터 DB를 관리합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_16272\\2940869297.py:78: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"bge-m3\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM으로 Groq 모델 (llama3-8b-8192)을 사용합니다.\n",
      "\n",
      "--- ☕️ 카페 챗봇에 오신 것을 환영합니다! ---\n",
      "메뉴, 가격, 추천 등에 대해 물어보실 수 있습니다. '종료'라고 입력하면 대화가 끝납니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, TypedDict, Annotated\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# LangChain 관련\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# LangGraph 관련\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# LangChain Community 및 기타\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "# --- 환경 변수 로드 ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- 사용자 상태 정의 ---\n",
    "class CafeState(TypedDict):\n",
    "    \"\"\"\n",
    "    카페 챗봇의 상태를 정의합니다.\n",
    "    'messages' 필드는 add_messages를 통해 LangGraph가 자동으로 관리합니다.\n",
    "    \"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    question_type: str | None = None  # 분류된 질문 유형\n",
    "\n",
    "\n",
    "# --- 벡터 DB 생성 및 로드 ---\n",
    "DATA_DIR = \"./data\"\n",
    "DB_PATH = \"./db/cafe_db\"\n",
    "MENU_DATA_FILE = os.path.join(DATA_DIR, \"cafe_menu_data.txt\")\n",
    "\n",
    "# 데이터 파일이 없으면 생성\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "if not os.path.exists(MENU_DATA_FILE):\n",
    "    print(f\"⚠️ '{MENU_DATA_FILE}' 파일이 없어 예시 데이터를 생성합니다.\")\n",
    "    with open(MENU_DATA_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"아메리카노: 신선한 에스프레소에 물을 더한 클래식 커피. ₩4,000\\n\")\n",
    "        f.write(\"카페 라떼: 부드러운 우유와 에스프레소의 조화. ₩4,500\\n\")\n",
    "        f.write(\"바닐라 라떼: 달콤한 바닐라 시럽이 들어간 라떼. ₩5,000\\n\")\n",
    "        f.write(\"카푸치노: 풍성한 우유 거품이 올라간 커피. ₩4,500\\n\")\n",
    "        f.write(\"초콜릿 라떼: 진한 초콜릿과 우유가 만난 음료. ₩5,500\\n\")\n",
    "        f.write(\"딸기 스무디: 신선한 딸기로 만든 상큼한 스무디. ₩6,000\\n\")\n",
    "        f.write(\"블루베리 베이글: 크림치즈와 잘 어울리는 블루베리 베이글. ₩3,500\\n\")\n",
    "        f.write(\"치즈 케이크: 부드럽고 진한 치즈의 맛. ₩6,500\\n\")\n",
    "        f.write(\"에그 샌드위치: 신선한 재료로 만든 든든한 샌드위치. ₩5,800\\n\")\n",
    "    \n",
    "    if os.path.exists(DB_PATH):\n",
    "        shutil.rmtree(DB_PATH)\n",
    "    print(\"✅ 예시 데이터 파일이 생성되었습니다. 벡터 DB를 새로 생성하려면 스크립트를 다시 실행해주세요.\")\n",
    "    exit()\n",
    "\n",
    "# 벡터 DB가 없으면 생성하고, 있으면 로드\n",
    "if not os.path.exists(DB_PATH):\n",
    "    print(\"✅ 벡터 DB가 없어 새로 생성합니다...\")\n",
    "    os.makedirs(DB_PATH, exist_ok=True)\n",
    "    loader = TextLoader(MENU_DATA_FILE, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    \n",
    "    embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "    db = FAISS.from_documents(chunks, embeddings)\n",
    "    db.save_local(DB_PATH)\n",
    "    print(\"✅ 벡터 DB 생성이 완료되었습니다.\")\n",
    "else:\n",
    "    print(\"✅ 벡터 DB가 이미 존재합니다.\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "menu_db = FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "print(f\"Ollama Embeddings 모델 (bge-m3)을 사용하여 벡터 DB를 관리합니다.\")\n",
    "\n",
    "# --- 정보 추출 함수 ---\n",
    "def extract_menu_info(doc: Document) -> dict:\n",
    "    \"\"\"Vector DB 문서에서 구조화된 메뉴 정보 (이름, 가격, 설명)를 추출합니다.\"\"\"\n",
    "    content = doc.page_content\n",
    "    name_match = re.match(r'([^:]+):', content)\n",
    "    menu_name = name_match.group(1).strip() if name_match else 'Unknown'\n",
    "    price_match = re.search(r'₩([\\d,]+)', content)\n",
    "    price = price_match.group(0) if price_match else \"가격 정보 없음\"\n",
    "    description = content\n",
    "    if name_match:\n",
    "        description = description.replace(name_match.group(0), \"\", 1).strip()\n",
    "    if price_match:\n",
    "        description = description.replace(price, \"\").strip()\n",
    "    if description.startswith(\":\"):\n",
    "        description = description[1:].strip()\n",
    "    return {\"name\": menu_name, \"price\": price, \"description\": description or \"설명 없음\"}\n",
    "\n",
    "# --- LLM 초기화 (Groq 사용) ---\n",
    "llm = ChatGroq(model_name=\"llama3-8b-8192\", temperature=0.7)\n",
    "print(f\"LLM으로 Groq 모델 ({llm.model_name})을 사용합니다.\")\n",
    "\n",
    "# --- 응답 생성 유틸리티 함수 ---\n",
    "def generate_llm_response(current_messages: List[BaseMessage], context: str, user_query: str) -> str:\n",
    "    \"\"\"주어진 컨텍스트와 사용자 쿼리, 대화 이력을 바탕으로 LLM 응답을 생성합니다.\"\"\"\n",
    "    recent_history = current_messages[-5:]\n",
    "    messages_for_llm = recent_history + [\n",
    "        HumanMessage(content=f\"다음 정보를 바탕으로 고객의 질문에 친절하고 간결하게 답변해주세요. 정보:\\n{context}\\n\\n고객 질문: {user_query}\")\n",
    "    ]\n",
    "    response = llm.invoke(messages_for_llm)\n",
    "    return response.content\n",
    "\n",
    "# --- 노드 함수 정의 ---\n",
    "\n",
    "def classify_question_node(state: CafeState) -> dict:\n",
    "    \"\"\"사용자 문의 유형을 분류하여 state의 question_type을 업데이트합니다.\"\"\"\n",
    "    last_message_content = state['messages'][-1].content.lower()\n",
    "    \n",
    "    if \"가격\" in last_message_content or \"얼마\" in last_message_content:\n",
    "        q_type = \"price\"\n",
    "    elif \"추천\" in last_message_content or \"좋은\" in last_message_content or \"인기\" in last_message_content:\n",
    "        q_type = \"recommend\"\n",
    "    elif any(keyword in last_message_content for keyword in [\"메뉴\", \"디저트\", \"라떼\", \"뭐\", \"어떤\", \"종류\", \"있나요\"]):\n",
    "        q_type = \"menu\"\n",
    "    else:\n",
    "        q_type = \"general\"\n",
    "    # 상태 업데이트를 위해 딕셔너리를 반환합니다.\n",
    "    return {\"question_type\": q_type}\n",
    "\n",
    "def route_question(state: CafeState) -> str:\n",
    "    \"\"\"state에 저장된 question_type에 따라 다음에 실행할 노드 이름을 반환합니다.\"\"\"\n",
    "    return state[\"question_type\"]\n",
    "\n",
    "def answer_price(state: CafeState) -> dict:\n",
    "    query = state['messages'][-1].content\n",
    "    docs = menu_db.similarity_search(query + \" 가격\", k=5)\n",
    "    items = [extract_menu_info(doc) for doc in docs]\n",
    "    if items:\n",
    "        context_str = \"\\n\".join([f\"- {i['name']}: {i['price']} ({i['description']})\" for i in items])\n",
    "        response_content = generate_llm_response(state['messages'], context_str, query)\n",
    "    else:\n",
    "        response_content = \"죄송합니다. 요청하신 메뉴의 가격 정보를 찾을 수 없습니다. 어떤 메뉴의 가격이 궁금하신가요?\"\n",
    "    return {\"messages\": [AIMessage(content=response_content)]}\n",
    "\n",
    "def answer_recommend(state: CafeState) -> dict:\n",
    "    query = state['messages'][-1].content\n",
    "    docs = menu_db.similarity_search(query, k=3)\n",
    "    if not docs:\n",
    "        docs = menu_db.similarity_search(\"인기 메뉴\", k=3)\n",
    "    items = [extract_menu_info(doc) for doc in docs]\n",
    "    if items:\n",
    "        context_str = \"\\n\".join([f\"추천 메뉴: {i['name']} - {i['description']} ({i['price']})\" for i in items])\n",
    "        response_content = generate_llm_response(state['messages'], context_str, query)\n",
    "    else:\n",
    "        response_content = \"지금 추천해 드릴 만한 특별한 메뉴를 찾을 수 없습니다. 어떤 종류의 메뉴를 선호하시나요?\"\n",
    "    return {\"messages\": [AIMessage(content=response_content)]}\n",
    "\n",
    "def answer_menu(state: CafeState) -> dict:\n",
    "    query = state['messages'][-1].content\n",
    "    docs = menu_db.similarity_search(query, k=4)\n",
    "    if not docs:\n",
    "        response_content = \"죄송합니다. 해당 메뉴 정보를 찾을 수 없습니다. 메뉴 이름을 정확히 말씀해주시겠어요?\"\n",
    "    else:\n",
    "        items = [extract_menu_info(doc) for doc in docs]\n",
    "        context_str = \"\\n\".join([f\"{i['name']}: {i['description']} ({i['price']})\" for i in items])\n",
    "        response_content = generate_llm_response(state['messages'], context_str, query)\n",
    "    return {\"messages\": [AIMessage(content=response_content)]}\n",
    "\n",
    "def fallback_answer(state: CafeState) -> dict:\n",
    "    query = state['messages'][-1].content\n",
    "    response_content = generate_llm_response(state['messages'], \"특별한 메뉴 정보 없음\", query)\n",
    "    return {\"messages\": [AIMessage(content=response_content)]}\n",
    "\n",
    "\n",
    "# --- LangGraph 그래프 구성 (수정된 부분) ---\n",
    "graph = StateGraph(CafeState)\n",
    "\n",
    "# 각 노드를 문자열 이름과 함께 추가합니다.\n",
    "graph.add_node(\"classify\", classify_question_node)\n",
    "graph.add_node(\"price\", answer_price)\n",
    "graph.add_node(\"recommend\", answer_recommend)\n",
    "graph.add_node(\"menu\", answer_menu)\n",
    "graph.add_node(\"general\", fallback_answer)\n",
    "\n",
    "# 진입점을 'classify' 노드로 설정합니다.\n",
    "graph.set_entry_point(\"classify\")\n",
    "\n",
    "# 'classify' 노드에서 시작하는 조건부 엣지를 추가합니다.\n",
    "graph.add_conditional_edges(\n",
    "    source=\"classify\",\n",
    "    path=route_question,\n",
    "    path_map={\n",
    "        \"price\": \"price\",\n",
    "        \"recommend\": \"recommend\",\n",
    "        \"menu\": \"menu\",\n",
    "        \"general\": \"general\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 각 응답 노드는 대화를 종료(END)합니다.\n",
    "graph.add_edge(\"price\", END)\n",
    "graph.add_edge(\"recommend\", END)\n",
    "graph.add_edge(\"menu\", END)\n",
    "graph.add_edge(\"general\", END)\n",
    "\n",
    "\n",
    "# --- 그래프 컴파일 ---\n",
    "app = graph.compile()\n",
    "\n",
    "# --- 챗봇 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- ☕️ 카페 챗봇에 오신 것을 환영합니다! ---\")\n",
    "    print(\"메뉴, 가격, 추천 등에 대해 물어보실 수 있습니다. '종료'라고 입력하면 대화가 끝납니다.\")\n",
    "    \n",
    "    messages = []\n",
    "    while True:\n",
    "        user_input = input(\"\\n💁‍♂️ 고객님: \")\n",
    "        if user_input.lower() == \"종료\":\n",
    "            print(\"👋 챗봇: 다음에 또 만나요!\")\n",
    "            break\n",
    "\n",
    "        input_message = HumanMessage(content=user_input)\n",
    "        \n",
    "        result = app.invoke({\"messages\": messages + [input_message]})\n",
    "\n",
    "        ai_response_message = result[\"messages\"][-1]\n",
    "        print(f\"🤖 챗봇: {ai_response_message.content}\")\n",
    "        \n",
    "        # 다음 대화를 위해 전체 메시지 이력 업데이트\n",
    "        messages = result[\"messages\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
